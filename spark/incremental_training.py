"""
Incremental (Feedback) Training Script for AutoEncoder
======================================================
ğŸ”„ ä¿®æ”¹ç‚¹ï¼ˆæŒ‰ä½ çš„éœ€æ±‚ï¼‰ï¼š
- å¢é‡è®­ç»ƒå®Œæˆåï¼Œä¸è¦†ç›– prediction_model
- æ–°å»ºä¸€ä¸ªåŒçº§ç›®å½•ï¼šfeedback_model
- å°†æ¨¡å‹å’Œ threshold ä¿å­˜åˆ° feedback_model
======================================================
"""

import os
import torch
import joblib
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from semantic_train import AutoEncoder

# ==========================================================
# è·¯å¾„é…ç½®
# ==========================================================
BASE_DIR = "/opt/spark/work-dir"

MODEL_DIR = f"{BASE_DIR}/models/prediction_model"  # åŸæ¨¡å‹ç›®å½•
FEEDBACK_MODEL_DIR = f"{BASE_DIR}/models/feedback_model"  # æ–°çš„åé¦ˆæ¨¡å‹ç›®å½•

FEEDBACK_FILE = f"{BASE_DIR}/data/feedback_samples.jsonl"
SCALER_FILE = f"{MODEL_DIR}/scaler.pkl"
MODEL_FILE = f"{MODEL_DIR}/autoencoder.pth"  # åŸæ¨¡å‹
THRESH_FILE = f"{MODEL_DIR}/threshold.pkl"

MODEL_NAME = "all-MiniLM-L12-v2"
hidden_dim = 64

# ==========================================================
# Step 1. åŠ è½½å¢é‡æ•°æ®
# ==========================================================
if not os.path.exists(FEEDBACK_FILE) or os.path.getsize(FEEDBACK_FILE) == 0:
    print("âš ï¸ No new feedback samples found. Skip retraining.")
    exit(0)

df = pd.read_json(FEEDBACK_FILE, lines=True)
if df.empty:
    print("âš ï¸ Feedback file is empty. Skip retraining.")
    exit(0)

texts = df["semantic_text"].tolist()
print(f"ğŸ“¦ Loaded {len(texts)} new feedback samples.")

# ==========================================================
# Step 2. ç¼–ç ä¸æ ‡å‡†åŒ–
# ==========================================================
encoder = SentenceTransformer(MODEL_NAME)
scaler = joblib.load(SCALER_FILE)

X = encoder.encode(texts)
X_scaled = scaler.transform(X).astype(np.float32)
X_tensor = torch.tensor(X_scaled)

# ==========================================================
# Step 3. åŠ è½½æ—§æ¨¡å‹
# ==========================================================
model = AutoEncoder(input_dim=X_tensor.shape[1], hidden_dim=hidden_dim)
model.load_state_dict(torch.load(MODEL_FILE))
model.encoder[2].p = 0.0
model.train()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
X_tensor = X_tensor.to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = torch.nn.MSELoss()

# ==========================================================
# Step 4. å¾®æ‰¹å¢é‡è®­ç»ƒ
# ==========================================================
EPOCHS = 10
print(f"ğŸš€ Starting incremental fine-tuning for {EPOCHS} epochs...")
for epoch in range(EPOCHS):
    optimizer.zero_grad()
    recon = model(X_tensor)
    loss = criterion(recon, X_tensor)
    loss.backward()
    optimizer.step()
    print(f"Epoch [{epoch+1}/{EPOCHS}] - Loss: {loss.item():.6f}")

# ==========================================================
# Step 5. æ›´æ–°é˜ˆå€¼
# ==========================================================
model.eval()
with torch.no_grad():
    reconstructed = model(X_tensor)
    mse = torch.mean((X_tensor - reconstructed) ** 2, dim=1).cpu().numpy()

threshold = float(np.percentile(mse, 97.5))
mean_mse = float(np.mean(mse))

print(f"ğŸ“Š Computed 97.5th percentile threshold: {threshold:.6f}")
print(f"ğŸ“ˆ Mean MSE after incremental training: {mean_mse:.6f}")

# ==========================================================
# Step 6. ä¿å­˜åˆ°æ–°çš„ feedback_model ç›®å½•
# ==========================================================
os.makedirs(FEEDBACK_MODEL_DIR, exist_ok=True)

FEEDBACK_MODEL_FILE = f"{FEEDBACK_MODEL_DIR}/autoencoder_feedback.pth"
FEEDBACK_THRESH_FILE = f"{FEEDBACK_MODEL_DIR}/threshold_feedback.pkl"

torch.save(model.state_dict(), FEEDBACK_MODEL_FILE)
joblib.dump(threshold, FEEDBACK_THRESH_FILE)

print(f"ğŸ’¾ Feedback model saved to: {FEEDBACK_MODEL_FILE}")
print(f"ğŸ’¾ Feedback threshold saved to: {FEEDBACK_THRESH_FILE}")

# ==========================================================
# Step 7. ä¸è¦†ç›– prediction_modelï¼Œä¹Ÿä¸æ¸…ç©º feedback æ–‡ä»¶ï¼ˆæŒ‰éœ€æ‰“å¼€ï¼‰
# ==========================================================
# open(FEEDBACK_FILE, "w").close()
# print("ğŸ§¹ Feedback file cleared.\n")

print("âœ… Incremental AutoEncoder feedback fine-tuning completed.\n")
