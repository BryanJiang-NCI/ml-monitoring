"""
root_cause_listener.py
=========================
ğŸ—ï¸ Event-driven Root Cause Inference on Spark
------------------------------------------------
æŒç»­ç›‘å¬ feedback_samples.jsonl æ–‡ä»¶ï¼Œ
å½“å‘ç°æ–°çš„äººå·¥ç¡®è®¤å¼‚å¸¸ï¼ˆfeedback_label=trueï¼‰æ—¶ï¼Œ
è‡ªåŠ¨æ‰§è¡Œè¯­ä¹‰åŒ¹é…æ ¹å› åˆ†æå¹¶æ‰“å°ç»“æœã€‚

"""

import os
import json
import time
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer, util
from pyspark.sql import SparkSession

# ===============================
# ğŸ”§ åŸºç¡€è·¯å¾„é…ç½®
# ===============================
BASE_DIR = "/opt/spark/work-dir"
MODEL_PATH = f"{BASE_DIR}/models/root_cause_model"
CMDB_FILE = f"{BASE_DIR}/data/cmdb.jsonl"
FEEDBACK_FILE = f"{BASE_DIR}/data/feedback_samples.jsonl"

CHECK_INTERVAL = 5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡æ–°æ ·æœ¬
PROCESSED_RECORDS = set()  # è®°å½•å·²å¤„ç†çš„æ ·æœ¬è¡Œ

# ===============================
# âš™ï¸ åˆå§‹åŒ– Spark ä¸æ¨¡å‹
# ===============================
spark = SparkSession.builder.appName("RootCauseListener").getOrCreate()

print("ğŸš€ Starting Root Cause Listener (event-driven mode)...")
print(f"ğŸ“¡ Monitoring feedback file: {FEEDBACK_FILE}")

encoder = SentenceTransformer(MODEL_PATH)
cmdb = pd.read_json(CMDB_FILE, lines=True)
entities = cmdb["service_name"].tolist()
entity_vecs = encoder.encode(entities, convert_to_tensor=True)


# ===============================
# ğŸ§  æ ¹å› åˆ†æå‡½æ•°
# ===============================
def infer_root_cause(anomaly_text: str, top_k: int = 3):
    anomaly_vec = encoder.encode(anomaly_text, convert_to_tensor=True)
    cos_scores = util.cos_sim(anomaly_vec, entity_vecs)[0]
    top_results = np.argsort(-cos_scores)[:top_k]
    results = [
        {"entity": entities[i], "confidence": float(cos_scores[i])} for i in top_results
    ]
    return results


# ===============================
# ğŸ” æ–‡ä»¶ç›‘å¬å¾ªç¯
# ===============================
while True:
    try:
        if not os.path.exists(FEEDBACK_FILE):
            time.sleep(CHECK_INTERVAL)
            continue

        with open(FEEDBACK_FILE, "r") as f:
            for line in f:
                if not line.strip() or line in PROCESSED_RECORDS:
                    continue

                PROCESSED_RECORDS.add(line)
                data = json.loads(line)

                # ä»…å¤„ç†äººå·¥ç¡®è®¤çš„å¼‚å¸¸
                if str(data.get("feedback_label", "")).lower() != "true":
                    continue

                text = data.get("semantic_text", "")
                if not text:
                    continue

                print("\nğŸ§© New confirmed anomaly detected!")
                print(f"â±ï¸ Timestamp: {data.get('timestamp')}")
                print(f"ğŸ§¾ Text: {text[:180]}...")

                # æ‰§è¡Œæ ¹å› åˆ†æ
                results = infer_root_cause(text)
                print("ğŸ” Root Cause Candidates:")
                for r in results:
                    print(f" - {r['entity']} (confidence={r['confidence']:.3f})")

                print("âœ… Root cause inference completed.\n")

        time.sleep(CHECK_INTERVAL)

    except Exception as e:
        print(f"âš ï¸ Listener error: {e}")
        time.sleep(CHECK_INTERVAL)
