"""
Isolation Forest Training Script
===============================
âœ… ä» Parquet æ–‡ä»¶è¯»å–åµŒå…¥å‘é‡
âœ… è®­ç»ƒ IsolationForest å¼‚å¸¸æ£€æµ‹æ¨¡å‹
âœ… è®¡ç®—å¼‚å¸¸åˆ†æ•°é˜ˆå€¼ï¼ˆ97.5åˆ†ä½ï¼‰
âœ… ä¿å­˜æ¨¡å‹ä¸ scaler
===============================
"""

import os
import glob
import joblib
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from tqdm import tqdm

# ======================
# è·¯å¾„é…ç½®
# ======================
PARQUET_DIR = "/opt/spark/work-dir/data/semantic_vectors"
MODEL_DIR = "/opt/spark/work-dir/models/iforest_model"
os.makedirs(MODEL_DIR, exist_ok=True)

# ======================
# Step 1. åŠ è½½æ‰€æœ‰ Parquet æ–‡ä»¶
# ======================
print(f"ğŸ“‚ Loading parquet files from: {PARQUET_DIR}")
files = glob.glob(os.path.join(PARQUET_DIR, "*.parquet"))
dfs = []

for f in tqdm(files, desc="ğŸ“¥ Reading parquet files"):
    try:
        df = pd.read_parquet(f)
        if "embedding" in df.columns:
            valid_df = df[["embedding"]].dropna()
            dfs.append(valid_df)
    except Exception as e:
        print(f"âš ï¸ Skip {f}: {e}")

df = pd.concat(dfs, ignore_index=True)
X = np.stack(df["embedding"].to_numpy())
print(f"âœ… Loaded {len(X)} samples with shape {X.shape}")

# ======================
# Step 2. æ ‡å‡†åŒ–
# ======================
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
joblib.dump(scaler, os.path.join(MODEL_DIR, "scaler.pkl"))
print("ğŸ’¾ Saved scaler.pkl")

# ======================
# Step 3. è®­ç»ƒ Isolation Forest
# ======================
model = IsolationForest(
    n_estimators=200,
    contamination=0.02,  # å‡è®¾ 2% å¼‚å¸¸
    random_state=42,
    max_samples="auto",
    n_jobs=-1,
)
print("ğŸš€ Training Isolation Forest...")
model.fit(X_scaled)

# ======================
# Step 4. è®¡ç®—å¼‚å¸¸åˆ†æ•°ä¸é˜ˆå€¼
# ======================
scores = -model.score_samples(X_scaled)
threshold = np.percentile(scores, 97.5)
print(f"ğŸ“Š Computed 97.5th percentile threshold: {threshold:.6f}")
print(f"ğŸ“ˆ Mean score: {np.mean(scores):.6f}")

# ======================
# Step 5. ä¿å­˜æ¨¡å‹ä¸é˜ˆå€¼
# ======================
joblib.dump(model, os.path.join(MODEL_DIR, "iforest.pkl"))
joblib.dump(threshold, os.path.join(MODEL_DIR, "threshold.pkl"))
print("ğŸ’¾ Model and threshold saved successfully.")
print(f"ğŸ“ Model directory: {MODEL_DIR}")
