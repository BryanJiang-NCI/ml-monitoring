"""
root_cause_train_stable_lean.py
======================================
ç¨³å®šå¼±ç›‘ç£ RCA è®­ç»ƒè„šæœ¬ (ç²¾ç®€ç‰ˆ)

å…³é”®ç‰¹æ€§ï¼š
1. ä¿æŒ CMDB/æœåŠ¡ä¾§ Embedding ç¨³å®šï¼ˆå†»ç»“ï¼‰
2. ä»…è®­ç»ƒ Log ä¾§çš„ Semantic Encoder
"""

import os
import re
import pandas as pd
from sentence_transformers import SentenceTransformer, InputExample, losses
from torch.utils.data import DataLoader

BASE_DIR = "/opt/spark/work-dir"
MODEL_SAVE_DIR = f"{BASE_DIR}/models/root_cause_model"
CMDB_FILE = f"{BASE_DIR}/data/cmdb.jsonl"
FEEDBACK_FILE = f"{BASE_DIR}/data/feedback_samples.jsonl"
MODEL_NAME = "all-MiniLM-L12-v2"
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)

# --- 1. CMDB åŠ è½½ä¸å®ä½“æ„å»º ---
cmdb = pd.read_json(CMDB_FILE, lines=True)

# å®ä½“æ–‡æœ¬æ„å»º (ä½¿ç”¨ lambda ç®€åŒ–)
cmdb["entity_text"] = cmdb.apply(
    lambda r: f"{r.get('service_name','')} {r.get('domain','')} {r.get('system','')} {' '.join(r.get('dependencies',[]))}",
    axis=1,
)
svc_map = dict(zip(cmdb["service_name"], cmdb["entity_text"]))
print(f"ğŸ“¦ Loaded {len(cmdb)} services.")


# --- 2. å¼±ç›‘ç£æ ‡ç­¾æå–å‡½æ•° ---
def extract_service(text, svc_names):
    # æŸ¥æ‰¾ URL æ¨¡å¼
    if m := re.search(r"http://([^:/]+)", text):
        return m.group(1)
    # æŸ¥æ‰¾æœåŠ¡åæ¨¡å¼
    matched = [s for s in svc_names if s in text]
    if matched:
        return matched[0]
    # æŸ¥æ‰¾ name= æ¨¡å¼
    if m := re.search(r"name=([a-zA-Z0-9_\-]+)", text):
        return m.group(1).split("_")[0]
    return None


# --- 3. æ•°æ®åŠ è½½ä¸æ ·æœ¬æ„å»º (æœ€ä¼˜åŒ–) ---
feedback = pd.read_json(FEEDBACK_FILE, lines=True)
feedback = feedback[feedback["feedback_label"] == "true"]
print(f"ğŸ“¦ Loaded {len(feedback)} confirmed anomalies.")

# åˆ—è¡¨æ¨å¯¼å¼æ„å»ºè®­ç»ƒæ ·æœ¬ (ä¸€è¡Œå®Œæˆç­›é€‰å’Œæ˜ å°„)
train_samples = [
    InputExample(texts=[row["semantic_text"], svc_map[pos_svc]])
    for _, row in feedback.iterrows()
    if (pos_svc := extract_service(row["semantic_text"], svc_map.keys()))  # æå–æœåŠ¡
    and pos_svc in svc_map  # ç¡®ä¿æœåŠ¡åœ¨ CMDB ä¸­
]

print(f"ğŸ¯ Training pairs: {len(train_samples)}")

# --- 4. ç¨³å®šè®­ç»ƒ (ä»…è®­ç»ƒ Semantic Encoder) ---
semantic_encoder = SentenceTransformer(MODEL_NAME)

train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=8)
train_loss = losses.MultipleNegativesRankingLoss(semantic_encoder)

print("ğŸš€ Training semantic-text encoder for RCA...")

# è®­ç»ƒé…ç½®
semantic_encoder.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=3,
    warmup_steps=50,
    show_progress_bar=True,
)

semantic_encoder.save(MODEL_SAVE_DIR)

print(f"ğŸ Stable RCA model saved to {MODEL_SAVE_DIR}")
