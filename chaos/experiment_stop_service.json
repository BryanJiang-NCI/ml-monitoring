{
    "version": "1.0.0",
    "title": "Benchmark Prometheus vs AI Monitor (Service Stop)",
    "description": "Stop the application container to simulate service outage and measure detection/recovery times across systems.",
    "steady-state-hypothesis": {
        "title": "Service container is running before injection",
        "probes": [
            {
                "type": "probe",
                "name": "check_container_running",
                "tolerance": [
                    0
                ],
                "provider": {
                    "type": "process",
                    "path": "bash",
                    "arguments": "-c 'docker inspect -f \"{{.State.Running}}\" fastapi-demo | grep -q true'"
                }
            }
        ]
    },
    "method": [
        {
            "type": "action",
            "name": "record_injection_time",
            "provider": {
                "type": "process",
                "path": "bash",
                "arguments": "-c 'echo \"inject_start $(python -c \"from datetime import datetime, timezone; print(datetime.now(timezone.utc).isoformat())\")\" > chaos/result/benchmark_service.log'"
            }
        },
        {
            "type": "action",
            "name": "inject_service_stop",
            "provider": {
                "type": "process",
                "path": "bash",
                "arguments": "-c 'docker stop fastapi-demo && sleep 30 && docker start fastapi-demo'"
            }
        },
        {
            "type": "probe",
            "name": "detect_prometheus_alert",
            "background": true,
            "provider": {
                "type": "process",
                "path": "python",
                "arguments": "chaos/probe_prometheus.py detect ServiceDown >> chaos/result/benchmark_service.log"
            }
        },
        {
            "type": "probe",
            "name": "detect_ai_alert",
            "background": true,
            "provider": {
                "type": "process",
                "path": "python",
                "arguments": "chaos/probe_ai_monitor.py detect >> chaos/result/benchmark_service.log"
            }
        },
        {
            "type": "probe",
            "name": "recover_prometheus",
            "background": true,
            "provider": {
                "type": "process",
                "path": "python",
                "arguments": "chaos/probe_prometheus.py recover ServiceDown >> chaos/result/benchmark_service.log"
            }
        },
        {
            "type": "probe",
            "name": "recover_ai_monitor",
            "background": true,
            "provider": {
                "type": "process",
                "path": "python",
                "arguments": "chaos/probe_ai_monitor.py recover >> chaos/result/benchmark_service.log"
            }
        }
    ]
}